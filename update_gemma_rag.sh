#!/bin/bash
set -e

# Define paths
APP_DIR="/opt/gemma-rag"
BACKUP_DIR="/opt/gemma-rag/backup_$(date +%Y%m%d_%H%M%S)"

echo "ğŸš€ Updating Gemma RAG Service..."

# 1. Backup current key files
echo "ğŸ“¦ Backing up current files to $BACKUP_DIR..."
mkdir -p $BACKUP_DIR
cp $APP_DIR/app/main.py $BACKUP_DIR/
cp $APP_DIR/rag/sqlite_engine.py $BACKUP_DIR/
cp $APP_DIR/.env $BACKUP_DIR/

# 2. Update sqlite_engine.py with multimodal support
echo "ğŸ“ Updating sqlite_engine.py..."
cat << 'PYTHON_EOF' > $APP_DIR/"rag/sqlite_engine.py
from __future__ import annotations

import os
import json
import sqlite3
import logging
from typing import Any, Dict, List, Optional

import boto3
import re

from .openrouter_client import OpenRouterClient


logger = logging.getLogger(__name__)


class SQLiteRAG:
    def __init__(
        self,
        *,
        db_path: str,
        index_bucket: Optional[str],
        index_prefix: str,
        sqlite_vec_so_path: str | None,  # unused in BM25-only mode
        openrouter: OpenRouterClient,
        topk: int = None,
        final_topn: int = None,
    ) -> None:
        self.db_path = db_path
        self.index_bucket = index_bucket
        self.index_prefix = index_prefix.rstrip("/") + "/"
        self.openrouter = openrouter
        self.topk = topk or int(os.getenv("RAG_TOPK", "50"))
        self.final_topn = final_topn or int(os.getenv("RAG_FINAL_TOPN", "10"))

        self._ensure_db_local()
        self.conn = self._open_sqlite()

    # ---------- Index bootstrap ----------
    def _ensure_db_local(self) -> None:
        if os.path.exists(self.db_path):
            return
        if not self.index_bucket:
            raise RuntimeError("Index not present and no index bucket configured")
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        s3 = boto3.client("s3")
        key = f"{self.index_prefix}rag.sqlite"
        logger.info("Downloading rag.sqlite from s3://%s/%s", self.index_bucket, key)
        s3.download_file(self.index_bucket, key, self.db_path)

    def reload_index(self) -> None:
        if not self.index_bucket:
            raise RuntimeError("No index bucket configured")
        s3 = boto3.client("s3")
        key = f"{self.index_prefix}rag.sqlite"
        logger.info("Reloading rag.sqlite from s3://%s/%s", self.index_bucket, key)
        s3.download_file(self.index_bucket, key, self.db_path)
        try:
            self.conn.close()
        except Exception:
            pass
        self.conn = self._open_sqlite()

    # ---------- SQLite helpers ----------
    def _open_sqlite(self) -> sqlite3.Connection:
        conn = sqlite3.connect(self.db_path, check_same_thread=False)
        return conn

    def _bm25_candidates(self, query: str, k: int) -> List[int]:
        # Build an OR expression across meaningful keywords for broader recall
        tokens = re.findall(r"\w+", query.lower())
        keywords = [t for t in tokens if len(t) >= 3]
        if not keywords:
            return []
        match_expr = " OR ".join(keywords)

        # FTS5 MATCH with OR; inline LIMIT to avoid param near MATCH
        fts_sql = (
            f"SELECT rowid, bm25(docs_fts) AS score FROM docs_fts "
            f"WHERE docs_fts MATCH '{match_expr}' ORDER BY score LIMIT {int(k)}"
        )
        cur = self.conn.execute(fts_sql)
        ids = [r[0] for r in cur.fetchall()]

        # Fallback: LIKE search if FTS returns nothing
        if not ids:
            like_clause = " OR ".join(["text LIKE ?"] * len(keywords))
            like_params = [f"%{t}%" for t in keywords]
            like_sql = f"SELECT id FROM docs WHERE {like_clause} LIMIT {int(k)}"
            cur = self.conn.execute(like_sql, like_params)
            ids = [r[0] for r in cur.fetchall()]

        return ids

    def _fetch_docs(self, ids: List[int]) -> List[Dict[str, Any]]:
        if not ids:
            return []
        placeholders = ",".join(["?"] * len(ids))
        sql = f"SELECT id, text, meta FROM docs WHERE id IN ({placeholders})"
        cur = self.conn.execute(sql, ids)
        out: List[Dict[str, Any]] = []
        for id_, text, meta in cur.fetchall():
            out.append({"id": id_, "text": text, "meta": json.loads(meta) if meta else None})
        return out

    def _format_context(self, chunks: List[Dict[str, Any]]) -> str:
        if not chunks:
            return "No relevant documents found."
        formatted: List[str] = []
        total = 0
        max_len = 1500 * 6
        for ch in chunks:
            txt = ch["text"]
            snippet = (txt[:800] + "...") if len(txt) > 800 else txt
            source = ch.get("meta", {}).get("file", "")
            block = f"Source: {source}\n{snippet}"
            if total + len(block) > max_len:
                break
            formatted.append(block)
            total += len(block)
        return "\n\n".join(formatted)

    # ---------- Public API ----------
    def stats(self) -> Dict[str, Any]:
        try:
            cur = self.conn.execute("SELECT COUNT(*) FROM docs")
            (n_docs,) = cur.fetchone()
        except Exception:
            n_docs = 0
        return {"documents": n_docs, "index_bucket": self.index_bucket, "index_prefix": self.index_prefix}

    def generate_answer(
        self,
        *,
        query: str,
        conversation_history: Optional[List[Dict[str, str]]] = None,
        translate: bool = True,
        top_k: int = 5,
        image_url: Optional[str] = None,
        image_base64: Optional[str] = None,
        metrics: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        k = max(self.topk, top_k)
        bm25_ids = self._bm25_candidates(query, k)
        final_ids = bm25_ids[: self.final_topn]
        docs = self._fetch_docs(final_ids)

        context = self._format_context(docs)

        sys_prompt = """
**é‡è¦ï¼šæ‚¨å¿…é ˆå…¨ç¨‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›è¦†ã€‚ä¸å¯ä½¿ç”¨è‹±æ–‡ã€‚**
**IMPORTANT: You MUST respond ENTIRELY in Traditional Chinese (ç¹é«”ä¸­æ–‡). Do NOT use English.**

æ‚¨æ˜¯ **ä½•æ¨‚å¨é†«å¸« (Dr. HoloWellness)**ï¼Œä¸€ä½è¬¹æ…ã€å…·å‚™ç”Ÿç‰©åŠ›å­¸å°ˆæ¥­çŸ¥è­˜çš„è™›æ“¬è‡¨åºŠé†«å¸«ã€‚

æ‚¨çš„ä¸»è¦ä»»å‹™æ˜¯å°‡åŸå§‹å§¿å‹¢æ•¸æ“šè½‰åŒ–ç‚ºæ¸…æ™°ã€æ˜“æ‡‚çš„æ‘˜è¦ï¼Œä¸¦æä¾›æº«å’Œã€è‡¨åºŠå®‰å…¨çš„æŒ‡å°å»ºè­°ã€‚

### 1. æ‚¨æœƒæ”¶åˆ°çš„è¼¸å…¥

æ‚¨å¯èƒ½æœƒæ”¶åˆ°ï¼š

- ä¸€çµ„çµæ§‹åŒ–çš„å§¿å‹¢æ•¸æ“šï¼ˆåç¨±å’Œæ•¸å€¼ï¼‰ï¼Œä¾‹å¦‚ï¼š
  - cervical_lateral_shift é ¸æ¤å´å‘åç§» (%)
  - pelvic_obliquity éª¨ç›†å‚¾æ–œ (Â°)
  - knee_valgus_left / knee_valgus_right è†å¤–ç¿»å·¦/å³ (Â°)
  - elbow_carry_angle_left / elbow_carry_angle_right è‚˜é—œç¯€ææ”œè§’å·¦/å³ (Â°)
  - neck_forward_head é ­éƒ¨å‰å‚¾ (Â°) ä¾†è‡ªå·¦å´å’Œå³å´è¦–åœ–
  - thoracic_hypokyphosis èƒ¸æ¤å¾Œå‡¸ä¸è¶³ (Â°) å’Œ thoracic_kyphosis_angle èƒ¸æ¤å¾Œå‡¸è§’åº¦ (Â°)
  - foot_progression_angle_left / foot_progression_angle_right è¶³éƒ¨å‰é€²è§’å·¦/å³ (Â°)

- å¯é¸çš„å…ƒæ•¸æ“šï¼Œå¦‚å§¿å‹¢é¡å‹ï¼ˆå¦‚ã€Œç«™ç«‹ã€ã€ã€Œæ·±è¹²ã€ï¼‰ã€å¹´é½¡ã€æ€§åˆ¥å’Œå…ˆå‰çš„æ¸¬é‡æ•¸æ“šã€‚

- å¯é¸çš„æª¢ç´¢ä¸Šä¸‹æ–‡ï¼Œè§£é‡‹é€™äº›æ•¸æ“šå¦‚ä½•è¨ˆç®—ã€å…¸å‹çš„æ­£å¸¸ç¯„åœï¼Œä»¥åŠåˆ†é¡æ¨™ç±¤å¦‚ã€ŒOKã€ã€ã€ŒPartialã€æˆ–ã€ŒSevereã€ã€‚

å°‡ç³»çµ±æä¾›çš„æ•¸å€¼å’Œåˆ†é¡æ¨™ç±¤è¦–ç‚ºæ­£ç¢ºã€‚ä½¿ç”¨æª¢ç´¢çš„ä¸Šä¸‹æ–‡ä½œç‚ºæ­£å¸¸ç¯„åœå’Œå®šç¾©çš„åƒè€ƒï¼Œè€Œä¸æ˜¯è‡ªè¡Œç™¼æ˜æ•¸å€¼ã€‚

### 2. æ‚¨çš„ä¸»è¦ç›®æ¨™

å°æ–¼æ¯æ¢è¨Šæ¯ï¼š

1. **ç”¨ç™½è©±æ–‡è§£é‡‹å§¿å‹¢**
   - ä»¥1-2å¥è©±æ¦‚è¿°é–‹å§‹ï¼ˆä¾‹å¦‚ï¼šã€Œæ•´é«”ä¾†çœ‹ï¼Œæ‚¨çš„å§¿å‹¢å¤§è‡´å¹³è¡¡ï¼Œä½†é ­éƒ¨æœ‰äº›å‰å‚¾ï¼Œé›™è…³æœ‰äº›ä¸å°ç¨±ã€‚ã€ï¼‰
   - ç›¡é‡é¿å…å°ˆæ¥­è¡“èªï¼›å¦‚æœå¿…é ˆä½¿ç”¨æŠ€è¡“è¡“èªï¼Œè«‹ç°¡è¦å®šç¾©ã€‚

2. **ç¸½çµæ•¸æ“šçš„ä¸»è¦ç™¼ç¾**
   - å°‡æ¯å€‹ç›¸é—œæ•¸æ“šè½‰æ›ç‚ºç”¨æˆ¶å‹å¥½çš„é™³è¿°ï¼š
     - èªªæ˜æ˜¯å¦**åœ¨æ­£å¸¸ç¯„åœå…§**ã€**è¼•å¾®åå·®**æˆ–**æ˜é¡¯åå·®**ï¼ŒåŸºæ–¼æä¾›çš„é–¾å€¼å’Œåˆ†é¡æ¨™ç±¤ã€‚
     - ç•¶æœ‰æ„ç¾©æ™‚ï¼Œå¼·èª¿å·¦å³å…©å´çš„å·®ç•°ã€‚
   - æŒ‰èº«é«”å€åŸŸåˆ†çµ„ç™¼ç¾ï¼š
     - é ­éƒ¨å’Œé ¸éƒ¨ï¼ˆå¦‚é ­éƒ¨å‰å‚¾ã€é ¸æ¤å´å‘åç§»ï¼‰
     - è‚©è†€å’Œè»€å¹¹ï¼ˆå¦‚èƒ¸æ¤å¾Œå‡¸/å¾Œå‡¸ä¸è¶³ã€éª¨ç›†å‚¾æ–œï¼‰
     - è†è“‹å’Œè‚˜éƒ¨
     - è¶³éƒ¨ï¼ˆè¶³éƒ¨å‰é€²è§’/å…§å…«/å¤–å…«ï¼‰

3. **æä¾›æº«å’Œã€å¯è¡Œçš„æŒ‡å°**
   - æä¾›**ç°¡å–®ã€ä½é¢¨éšªçš„å»ºè­°**ï¼Œå°ˆæ³¨æ–¼ï¼š
     - å§¿å‹¢è¦ºå¯Ÿå’Œå°é½Šï¼ˆå¦‚ã€Œè¼•è¼•æ”¶ä¸‹å·´ã€ã€ã€Œé›™è…³å‡å‹»ç«™ç«‹ã€ï¼‰
     - éå¸¸åŸºç¤çš„æ´»å‹•åº¦/ä¼¸å±•ï¼ˆå¦‚æ“´èƒ¸ä¼¸å±•ã€é«–å±ˆè‚Œä¼¸å±•ï¼‰
     - éå¸¸åŸºç¤çš„åŠ›é‡/æ§åˆ¶ï¼ˆå¦‚ã€Œç·´ç¿’é ç‰†åŠè¹²ï¼Œä¿æŒè„ŠæŸ±ä¸­ç«‹ã€ï¼‰
   - ä¿æŒå»ºè­°**ä¸€èˆ¬åŒ–ä¸”ä»¥è‡ªèº«é«”é‡ç‚ºä¸»**ã€‚é¿å…é«˜è² è·æˆ–é€²éšé‹å‹•ã€‚
   - å¦‚æœåå·®è¼ƒæ˜é¡¯ï¼ˆå¦‚é ­éƒ¨å‰å‚¾å¢åŠ æˆ–è¶³éƒ¨è§’åº¦ç•°å¸¸ï¼‰ï¼Œå°‡å…¶æè¿°ç‚ºã€Œå€¼å¾—é—œæ³¨æ”¹å–„ã€è€Œéä»¤äººæ“”æ†‚ã€‚

4. **ä¿æŒè‡¨åºŠå®‰å…¨**
   - æ‚¨**ä¸æ˜¯**åœ¨åšé†«ç™‚è¨ºæ–·ã€‚
   - **ä¸è¦**è²ç¨±å¯ä»¥æ²»ç™’ã€æ²»ç™‚æˆ–é é˜²ç–¾ç—…ã€‚
   - å¦‚æœç”¨æˆ¶æåˆ°ï¼š
     - åš´é‡ç–¼ç—›
     - éº»æœ¨/åˆºç—›
     - è¿‘æœŸå¤–å‚·
     - æˆ–æ¼¸é€²æ€§ç—‡ç‹€
     å‰‡æ˜ç¢ºå»ºè­°ä»–å€‘å°‹æ±‚åˆæ ¼é†«ç™‚å°ˆæ¥­äººå“¡çš„ç¾å ´è©•ä¼°ã€‚
   - å¦‚æœæ•¸æ“šæ˜é¡¯è¶…å‡ºå…¸å‹ç¯„åœæˆ–çœ‹èµ·ä¾†ä¸ä¸€è‡´ï¼Œå»ºè­°é‡æ–°æƒæå’Œ/æˆ–é€²è¡Œç¾å ´è©•ä¼°ã€‚

### 3. å¦‚ä½•ä½¿ç”¨æ•¸æ“šå’Œåˆ†é¡

- å§‹çµ‚å„ªå…ˆä½¿ç”¨ç³»çµ±çš„**åˆ†é¡æ¨™ç±¤**ï¼ˆå¦‚ã€ŒOKã€ã€ã€ŒPartialã€ã€ã€ŒSevereã€æˆ–é¡ä¼¼ï¼‰ï¼Œä¸¦å°‡å…¶ç¿»è­¯ç‚ºç”¨æˆ¶å‹å¥½çš„ç¹é«”ä¸­æ–‡ï¼š
  - "OK" â†’ ã€Œåœ¨æ­£å¸¸ç¯„åœå…§ã€
  - "Partial" æˆ– "borderline" â†’ ã€Œæœ‰è¼•å¾®åå·®ï¼Œå€¼å¾—ç•™æ„ã€
  - "Severe" â†’ ã€Œæœ‰è¼ƒå¤§åå·®ï¼Œå»ºè­°å°‹æ±‚å°ˆæ¥­è©•ä¼°ã€

- ç•¶ä¸Šä¸‹æ–‡æä¾›æ˜ç¢ºçš„æ•¸å€¼é–¾å€¼æ™‚ï¼Œç”¨å®ƒä¾†æ”¯æŒæ‚¨çš„èªªæ³•ï¼Œä½†**ä¸è¦**å‘ç”¨æˆ¶å¼•ç”¨å¤ªå¤šæ•¸å­—ï¼Œé™¤éä»–å€‘è¦æ±‚ã€‚

- å¼·èª¿æ¨¡å¼è€Œéå€‹åˆ¥æ•¸å­—ï¼šä¾‹å¦‚ã€Œé›™è†æ¥è¿‘ä¸­ç«‹ä½ç½®ã€æˆ–ã€Œæ‚¨çš„é ­éƒ¨ç›¸å°æ–¼è‚©è†€æœ‰å‰å‚¾çš„å‚¾å‘ã€ã€‚

### 4. è·¨ç™‚ç¨‹æ¯”è¼ƒï¼ˆå¦‚é©ç”¨ï¼‰

- å¦‚æœæ‚¨æ”¶åˆ°å…ˆå‰ç™‚ç¨‹çš„æ•¸æ“šï¼Œç°¡è¦æ¯”è¼ƒï¼š
  - ã€Œèˆ‡ä¸Šæ¬¡æƒæç›¸æ¯”ï¼Œæ‚¨çš„é ­éƒ¨å‰å‚¾å§¿å‹¢ç•¥æœ‰æ”¹å–„ã€‚ã€
  - ã€Œæ‚¨çš„éª¨ç›†å‚¾æ–œèˆ‡ä¸Šæ¬¡ç™‚ç¨‹ç›¸ä¼¼ã€‚ã€
- ä¿æŒæ¯”è¼ƒç°¡å–®ä¸”å…·æ¿€å‹µæ€§ã€‚é¿å…è² é¢æˆ–ç¾è¾±æ€§èªè¨€ã€‚

### 5. æå•å¾ŒçºŒå•é¡Œ

åƒ…åœ¨è³‡è¨Š**ä¸è¶³ä»¥æä¾›å®‰å…¨ã€åŸºæœ¬æŒ‡å°**æ™‚æ‰æå•ã€‚åœ¨é€™ç¨®æƒ…æ³ä¸‹ï¼š
- æœ€å¤šå•**2-3å€‹ç°¡çŸ­ã€æœ‰é‡å°æ€§çš„å•é¡Œ**ï¼Œä¾‹å¦‚ï¼š
  - ã€Œæ‚¨ç›®å‰åœ¨æ—¥å¸¸æ´»å‹•ä¸­æ˜¯å¦æœ‰é ¸éƒ¨æˆ–èƒŒéƒ¨ç–¼ç—›ï¼Ÿã€
  - ã€Œæ‚¨æœ€è¿‘æ˜¯å¦æœ‰è†è“‹æˆ–è„ŠæŸ±å—å‚·ï¼Ÿã€
- æå•å¾Œï¼Œä»ç„¶æ ¹æ“šç¾æœ‰æ•¸æ“šæä¾›ä»»ä½•å¯èƒ½æœ‰å¹«åŠ©çš„è§£é‡‹ï¼Œè€Œä¸æ˜¯æ‹’çµ•å›ç­”ã€‚

### 6. é¢¨æ ¼å’Œèªæ°£

- èªæ°£ï¼šå†·éœã€æ”¯æŒã€é¼“å‹µã€ä¸æ‰¹åˆ¤ã€‚
- é•·åº¦ï¼š
  - ç›®æ¨™æ˜¯2-4å€‹çŸ­æ®µè½åŠ ä¸Š3-7å€‹è¦é»ç”¨æ–¼ç™¼ç¾æˆ–è¡Œå‹•æ­¥é©Ÿã€‚
  - ç°¡æ½”ä½†ä¸ç¥ç§˜ï¼›æ¸…æ™°æ¯”æ¥µåº¦ç°¡çŸ­æ›´é‡è¦ã€‚
- é¿å…ï¼š
  - åš‡å”¬ç”¨æˆ¶ã€‚
  - éåº¦æ‰¿è«¾çµæœã€‚
  - è¶…å‡ºæ•¸æ“šå’Œä¸Šä¸‹æ–‡é€²è¡Œæ¨æ¸¬ã€‚

### 7. ç•¶è³‡è¨Šç¼ºå¤±æˆ–ä¸æ¸…æ¥šæ™‚

- å¦‚æœæŸäº›æ•¸æ“šç¼ºå¤±æˆ–æ˜é¡¯ä¸ä¸€è‡´ï¼ˆå¦‚å·¦å³å€¼ä¸å¯èƒ½åŒæ™‚å­˜åœ¨ï¼‰ï¼Œç°¡è¦æ‰¿èªé€™ä¸€é»ä¸¦ï¼š
  - å»ºè­°é‡æ–°æƒæï¼Œå’Œ/æˆ–
  - å°ˆæ³¨æ–¼çœ‹èµ·ä¾†å¯é çš„æ•¸æ“šã€‚
- å¦‚æœæœªæä¾›å§¿å‹¢é¡å‹ï¼Œå‡è¨­ç‚ºä¸­ç«‹ç«™å§¿ï¼Œé™¤éæ˜ç¢ºèªªæ˜å¦å‰‡ï¼Œä¸¦æåŠè©²å‡è¨­ã€‚

å§‹çµ‚å„ªå…ˆè€ƒæ…®å®‰å…¨ã€æ¸…æ™°å’ŒåŒç†å¿ƒã€‚æ‚¨çš„å·¥ä½œæ˜¯å¹«åŠ©ç”¨æˆ¶ç”¨æ—¥å¸¸èªè¨€ç†è§£ä»–å€‘çš„å§¿å‹¢æ•¸æ“šæ„å‘³è‘—ä»€éº¼ï¼Œä¸¦çµ¦å‡ºæº«å’Œã€ç¾å¯¦çš„ä¸‹ä¸€æ­¥å»ºè­°ï¼Œè€Œä¸æ˜¯å–ä»£äººé¡è‡¨åºŠé†«å¸«ã€‚

**å†æ¬¡æé†’ï¼šæ‚¨çš„å›è¦†å¿…é ˆå…¨ç¨‹ä½¿ç”¨ç¹é«”ä¸­æ–‡ã€‚**
"""
        messages: List[Dict[str, Any]] = [{"role": "system", "content": sys_prompt}]
        if conversation_history:
            for m in conversation_history[-6:]:
                if m.get("content"):
                    messages.append({"role": m.get("role", "user"), "content": m["content"]})

        # Build user content with optional metrics and image (OpenAI-style multimodal content)
        user_parts: List[Dict[str, Any]] = []
        text_blocks: List[str] = [f"Context:\n{context}", f"Question: {query}"]
        if metrics:
            try:
                pretty_metrics = json.dumps(metrics, ensure_ascii=False, indent=2)
            except Exception:
                pretty_metrics = str(metrics)
            text_blocks.insert(1, f"Metrics (from system):\n{pretty_metrics}")
        user_parts.append({"type": "text", "text": "\n\n".join(text_blocks)})
        if image_url:
            user_parts.append({"type": "image_url", "image_url": {"url": image_url}})
        elif image_base64:
            user_parts.append({"type": "image_url", "image_url": {"url": f"data:image/png;base64,{image_base64}"}})

        if len(user_parts) == 1 and user_parts[0].get("type") == "text":
            messages.append({"role": "user", "content": user_parts[0]["text"]})
        else:
            messages.append({"role": "user", "content": user_parts})

        resp = self.openrouter.chat(messages)
        content = resp.get("message", {}).get("content", "")

        return {
            "content": content,
            "thinking": "",
            "retrieved_context": context,
            "sources": [{"id": d["id"], "meta": d.get("meta")} for d in docs],
            "reranked": False,
        }
PYTHON_EOF

# 3. Update app/main.py to parse new inputs
echo "ğŸ“ Updating app/main.py..."
cat << 'PYTHON_EOF' > $APP_DIR/app/main.py
from __future__ import annotations

import os
import logging
from typing import List, Optional, Dict, Any

import orjson
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

from rag.sqlite_engine import SQLiteRAG
from rag.openrouter_client import OpenRouterClient

try:
    import sentry_sdk  # type: ignore
    if os.getenv("SENTRY_DSN"):
        sentry_sdk.init(dsn=os.getenv("SENTRY_DSN"))
except Exception:
    pass


class Message(BaseModel):
    role: str
    content: str


class QueryRequest(BaseModel):
    query: str
    history: Optional[List[Message]] = None
    translate: Optional[bool] = True
    top_k: Optional[int] = 5
    # New: optional multimodal inputs
    image_url: Optional[str] = None
    image_base64: Optional[str] = None
    metrics: Optional[Dict[str, Any]] = None


class QueryResponse(BaseModel):
    content: str
    thinking: Optional[str] = None
    retrieved_context: Optional[str] = None
    sources: Optional[List[Dict[str, Any]]] = None
    reranked: Optional[bool] = False


def _json_dumps(v, *, default=None):
    return orjson.dumps(v, default=default).decode()


app = FastAPI()

logger = logging.getLogger("gemma-rag-service")
logging.basicConfig(level=os.getenv("LOG_LEVEL", "INFO"))


# Environment-driven configuration
DB_LOCAL_PATH = os.getenv("RAG_SQLITE_PATH", "/opt/gemma-rag/rag.sqlite")
SQLITE_VEC_SO_PATH = os.getenv("SQLITE_VEC_SO_PATH", "/opt/sqlite-vec/sqlite-vec0.so")
INDEX_BUCKET = os.getenv("RAG_INDEX_BUCKET")
INDEX_PREFIX = os.getenv("RAG_INDEX_PREFIX", "indexes/current/")


# Initialize engine and client once
openrouter = OpenRouterClient(
    api_key=os.getenv("OPENROUTER_API_KEY"),
    model=os.getenv("OPENROUTER_MODEL", "google/gemma-2b-it"),
)
rag_engine = SQLiteRAG(
    db_path=DB_LOCAL_PATH,
    index_bucket=INDEX_BUCKET,
    index_prefix=INDEX_PREFIX,
    sqlite_vec_so_path=SQLITE_VEC_SO_PATH,
    openrouter=openrouter,
)


@app.get("/health")
def health():
    try:
        stats = rag_engine.stats()
        return {"status": "ok", **stats}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/v1/rag/query", response_model=QueryResponse)
def query(req: QueryRequest):
    if not req.query or not str(req.query).strip():
        raise HTTPException(status_code=400, detail="query is required")
    try:
        result = rag_engine.generate_answer(
            query=req.query,
            conversation_history=[m.model_dump() for m in (req.history or [])],
            translate=bool(req.translate) if req.translate is not None else True,
            top_k=req.top_k or 5,
            image_url=req.image_url,
            image_base64=req.image_base64,
            metrics=req.metrics,
        )
        return result
    except HTTPException:
        raise
    except Exception as e:
        logger.exception("/v1/rag/query failed")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/v1/rag/reload")
def reload_index():
    try:
        rag_engine.reload_index()
        return {"status": "ok", "message": "Index reloaded"}
    except Exception as e:
        logger.exception("/v1/rag/reload failed")
        raise HTTPException(status_code=500, detail=str(e))
PYTHON_EOF

# 4. Restart service
echo "ğŸ”„ Restarting gemma-rag service..."
sudo systemctl restart gemma-rag
sleep 3
systemctl status gemma-rag --no-pager

echo "âœ… Gemma RAG Service updated successfully!"

